version: "3.8"

services:
  ingestor:
    build: ./services/ingestor
    container_name: ingestor
    environment:
      - PROGRAM_URL_AI=https://abit.itmo.ru/program/master/ai
      - PROGRAM_URL_AIPROD=https://abit.itmo.ru/program/master/ai_product
      - DATA_DIR=/app/data
    volumes:
      - ./data:/app/data
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]   # если есть NVIDIA
    command: ["python", "run.py"]

  api:
    build: ./services/api
    container_name: api
    environment:
      - MODEL_QWEN=Qwen/Qwen3-1.7B
      - DATA_DIR=/app/data
      - HF_HOME=/cache/hf
      - TORCH_USE_CUDA_DSA=0
    volumes:
      - ./data:/app/data
      - hf_cache:/cache/hf
    ports: ["8000:8000"]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]   # если есть NVIDIA

  bot:
    build: ./services/bot
    container_name: bot
    environment:
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - API_BASE=http://api:8000
    depends_on: [api]

volumes:
  qdrant_storage:
  hf_cache:
